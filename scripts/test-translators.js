/**
 * ç¿»è¯‘å™¨åŠŸèƒ½æµ‹è¯•è„šæœ¬
 * ç”¨äºéªŒè¯ç¿»è¯‘å™¨æ³¨å†Œè¡¨å’Œå„ä¸ªç¿»è¯‘å™¨çš„åŠŸèƒ½
 */

const path = require('path')

// è®¾ç½®ç¯å¢ƒå˜é‡
process.env.NODE_ENV = 'development'
process.env.LOG_LEVEL = 'debug'

// åŠ è½½ç¿»è¯‘å™¨æ¨¡å—
const { registry, Formats } = require('../src/translators')

console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')
console.log('â•‘             ğŸ§ª Translator System Test Suite                   â•‘')
console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')

// æµ‹è¯•æ•°æ®
const testCases = {
  openaiRequest: {
    model: 'gpt-4',
    messages: [
      { role: 'system', content: 'You are a helpful assistant.' },
      { role: 'user', content: 'Hello, how are you?' },
      { role: 'assistant', content: 'I am doing well, thank you!' },
      { role: 'user', content: 'What is the weather like?' }
    ],
    temperature: 0.7,
    max_tokens: 1000,
    stream: true
  },

  claudeRequest: {
    model: 'claude-3-5-sonnet-20241022',
    system: 'You are a helpful assistant.',
    messages: [
      {
        role: 'user',
        content: [{ type: 'text', text: 'Hello, how are you?' }]
      },
      {
        role: 'assistant',
        content: [{ type: 'text', text: 'I am doing well, thank you!' }]
      },
      {
        role: 'user',
        content: [{ type: 'text', text: 'What is the weather like?' }]
      }
    ],
    temperature: 0.7,
    max_tokens: 1000
  },

  claudeStreamResponse: {
    type: 'content_block_delta',
    index: 0,
    delta: { type: 'text_delta', text: 'Hello, ' }
  },

  claudeNonStreamResponse: {
    id: 'msg_01XFDUDYJgAACzvnptvVoYEL',
    type: 'message',
    role: 'assistant',
    content: [
      {
        type: 'text',
        text: 'Hello! The weather today is sunny with a temperature of 75Â°F.'
      }
    ],
    model: 'claude-3-5-sonnet-20241022',
    stop_reason: 'end_turn',
    usage: {
      input_tokens: 100,
      output_tokens: 50
    }
  },

  openaiStreamResponse: `data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}\n\n`,

  openaiNonStreamResponse: {
    id: 'chatcmpl-123',
    object: 'chat.completion',
    created: 1677652288,
    model: 'gpt-4',
    choices: [
      {
        index: 0,
        message: {
          role: 'assistant',
          content: 'Hello! The weather today is sunny with a temperature of 75Â°F.'
        },
        finish_reason: 'stop'
      }
    ],
    usage: {
      prompt_tokens: 100,
      completion_tokens: 50,
      total_tokens: 150
    }
  }
}

/**
 * æµ‹è¯•è¯·æ±‚ç¿»è¯‘
 */
function testRequestTranslation() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  console.log('ğŸ”„ Testing Request Translation')
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')

  // æµ‹è¯• OpenAI â†’ Claude
  console.log('1ï¸âƒ£  OpenAI â†’ Claude Request Translation')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  try {
    const translated = registry.translateRequest(Formats.OPENAI_CHAT, Formats.CLAUDE, {
      model: testCases.openaiRequest.model,
      rawRequest: testCases.openaiRequest,
      stream: true
    })

    console.log('âœ… Translation successful')
    console.log('Original messages count:', testCases.openaiRequest.messages.length)
    console.log('Translated messages count:', translated.messages.length)
    console.log('Has system prompt:', !!translated.system)
    console.log('Model:', translated.model)
    console.log('Max tokens:', translated.max_tokens)
    console.log()
  } catch (error) {
    console.error('âŒ Translation failed:', error.message)
    console.log()
  }

  // æµ‹è¯• Claude â†’ OpenAI
  console.log('2ï¸âƒ£  Claude â†’ OpenAI Request Translation')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  try {
    const translated = registry.translateRequest(Formats.CLAUDE, Formats.OPENAI_CHAT, {
      model: testCases.claudeRequest.model,
      rawRequest: testCases.claudeRequest,
      stream: false
    })

    console.log('âœ… Translation successful')
    console.log('Original messages count:', testCases.claudeRequest.messages.length)
    console.log('Translated messages count:', translated.messages.length)
    console.log('Has system message:', translated.messages.some((m) => m.role === 'system'))
    console.log('Model:', translated.model)
    console.log('Max tokens:', translated.max_tokens)
    console.log()
  } catch (error) {
    console.error('âŒ Translation failed:', error.message)
    console.log()
  }
}

/**
 * æµ‹è¯•å“åº”ç¿»è¯‘
 */
function testResponseTranslation() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  console.log('ğŸ”„ Testing Response Translation')
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')

  // æµ‹è¯• Claude Stream â†’ OpenAI Stream
  console.log('3ï¸âƒ£  Claude Stream â†’ OpenAI Stream Response Translation')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  try {
    const translated = registry.translateStreamResponse(Formats.OPENAI_CHAT, Formats.CLAUDE, {
      model: 'gpt-4',
      originalRequest: testCases.openaiRequest,
      translatedRequest: {},
      rawResponse: testCases.claudeStreamResponse
    })

    console.log('âœ… Translation successful')
    console.log('Output chunks:', translated.length)
    if (translated.length > 0) {
      console.log('First chunk preview:', translated[0].substring(0, 100))
    }
    console.log()
  } catch (error) {
    console.error('âŒ Translation failed:', error.message)
    console.log()
  }

  // æµ‹è¯• Claude NonStream â†’ OpenAI NonStream
  console.log('4ï¸âƒ£  Claude NonStream â†’ OpenAI NonStream Response Translation')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  try {
    const translated = registry.translateNonStreamResponse(Formats.OPENAI_CHAT, Formats.CLAUDE, {
      model: 'gpt-4',
      originalRequest: testCases.openaiRequest,
      translatedRequest: {},
      rawResponse: testCases.claudeNonStreamResponse
    })

    console.log('âœ… Translation successful')
    console.log('Response ID:', translated.id)
    console.log('Content length:', translated.choices[0].message.content.length)
    console.log('Finish reason:', translated.choices[0].finish_reason)
    console.log('Usage:', JSON.stringify(translated.usage))
    console.log()
  } catch (error) {
    console.error('âŒ Translation failed:', error.message)
    console.log()
  }

  // æµ‹è¯• OpenAI Stream â†’ Claude Stream
  console.log('5ï¸âƒ£  OpenAI Stream â†’ Claude Stream Response Translation')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  try {
    const translated = registry.translateStreamResponse(Formats.CLAUDE, Formats.OPENAI_CHAT, {
      model: 'claude-3-5-sonnet-20241022',
      originalRequest: testCases.claudeRequest,
      translatedRequest: {},
      rawResponse: testCases.openaiStreamResponse
    })

    console.log('âœ… Translation successful')
    console.log('Output chunks:', translated.length)
    if (translated.length > 0) {
      console.log('First chunk preview:', translated[0].substring(0, 100))
    }
    console.log()
  } catch (error) {
    console.error('âŒ Translation failed:', error.message)
    console.log()
  }

  // æµ‹è¯• OpenAI NonStream â†’ Claude NonStream
  console.log('6ï¸âƒ£  OpenAI NonStream â†’ Claude NonStream Response Translation')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  try {
    const translated = registry.translateNonStreamResponse(Formats.CLAUDE, Formats.OPENAI_CHAT, {
      model: 'claude-3-5-sonnet-20241022',
      originalRequest: testCases.claudeRequest,
      translatedRequest: {},
      rawResponse: testCases.openaiNonStreamResponse
    })

    console.log('âœ… Translation successful')
    console.log('Response ID:', translated.id)
    console.log('Content length:', translated.content[0].text.length)
    console.log('Stop reason:', translated.stop_reason)
    console.log('Usage:', JSON.stringify(translated.usage))
    console.log()
  } catch (error) {
    console.error('âŒ Translation failed:', error.message)
    console.log()
  }
}

/**
 * æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
 */
function testStatistics() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  console.log('ğŸ“Š Translation Statistics')
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')

  const stats = registry.getRuntimeStats()
  console.log('Registered Translators:')
  console.log('  - Request Translators:', stats.registered.requestTranslators)
  console.log('  - Response Translators:', stats.registered.responseTranslators)
  console.log()

  console.log('Runtime Statistics:')
  console.log('  - Request Translations:', stats.runtime.requestTranslations)
  console.log('  - Stream Translations:', stats.runtime.streamTranslations)
  console.log('  - NonStream Translations:', stats.runtime.nonStreamTranslations)
  console.log('  - Total Translations:', stats.runtime.totalTranslations)
  console.log('  - Errors:', stats.runtime.errors)
  console.log()

  const paths = registry.getRegisteredPaths()
  console.log('Available Translation Paths:')
  console.log('  Request Paths:', paths.request.join(', '))
  console.log('  Response Paths:', paths.response.join(', '))
  console.log()
}

/**
 * ä¸»æµ‹è¯•å‡½æ•°
 */
async function runTests() {
  try {
    // æ‰“å°æ³¨å†Œè¡¨ç»Ÿè®¡
    console.log('Initial Registry State:\n')
    registry.printStats()
    console.log()

    // è¿è¡Œæµ‹è¯•
    testRequestTranslation()
    testResponseTranslation()
    testStatistics()

    console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')
    console.log('â•‘              âœ… All tests completed successfully!              â•‘')
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')
  } catch (error) {
    console.error('\nâŒ Test suite failed:', error)
    process.exit(1)
  }
}

// è¿è¡Œæµ‹è¯•
runTests()
