const logger = require('../../utils/logger')

/**
 * Â∞Ü OpenAI Ê†ºÂºèÁöÑËØ∑Ê±ÇËΩ¨Êç¢‰∏∫ Claude Ê†ºÂºè
 * 
 * OpenAIÊ†ºÂºèÁ§∫‰æãÔºö
 * {
 *   model: "gpt-4",
 *   messages: [
 *     { role: "system", content: "You are a helpful assistant" },
 *     { role: "user", content: "Hello" }
 *   ],
 *   temperature: 0.7,
 *   max_tokens: 1000
 * }
 * 
 * ClaudeÊ†ºÂºèÁ§∫‰æãÔºö
 * {
 *   model: "claude-3-5-sonnet-20241022",
 *   system: "You are a helpful assistant",
 *   messages: [
 *     { role: "user", content: [{ type: "text", text: "Hello" }] }
 *   ],
 *   temperature: 0.7,
 *   max_tokens: 1000
 * }
 * 
 * @param {TranslateRequestOptions} options
 * @returns {Object} ClaudeÊ†ºÂºèÁöÑËØ∑Ê±Ç
 */
function translateOpenAIRequestToClaude({ model, rawRequest, stream, metadata }) {
  const claudeRequest = {
    model: model || rawRequest.model || 'claude-3-5-sonnet-20241022',
    max_tokens: rawRequest.max_tokens || 4096,
    stream: stream !== undefined ? stream : !!rawRequest.stream
  }

  // ËΩ¨Êç¢ messages
  const messages = []
  let systemPrompt = null

  for (const message of rawRequest.messages || []) {
    if (message.role === 'system') {
      // Claude ‰ΩøÁî®ÂçïÁã¨ÁöÑ system Â≠óÊÆµ
      systemPrompt = systemPrompt ? `${systemPrompt}\n\n${message.content}` : message.content
    } else if (message.role === 'user' || message.role === 'assistant') {
      // ËΩ¨Êç¢‰∏∫ Claude ÁöÑ content Ê†ºÂºè
      const content = []

      if (typeof message.content === 'string') {
        content.push({ type: 'text', text: message.content })
      } else if (Array.isArray(message.content)) {
        for (const part of message.content) {
          if (part.type === 'text') {
            content.push({ type: 'text', text: part.text })
          } else if (part.type === 'image_url') {
            // ËΩ¨Êç¢ÂõæÁâáÊ†ºÂºè
            const imageUrl = part.image_url?.url || part.image_url
            if (imageUrl.startsWith('data:')) {
              // base64Ê†ºÂºè
              const match = imageUrl.match(/^data:image\/(\w+);base64,(.+)$/)
              if (match) {
                content.push({
                  type: 'image',
                  source: {
                    type: 'base64',
                    media_type: `image/${match[1]}`,
                    data: match[2]
                  }
                })
              }
            } else {
              // URLÊ†ºÂºè
              content.push({
                type: 'image',
                source: {
                  type: 'url',
                  url: imageUrl
                }
              })
            }
          }
        }
      }

      messages.push({
        role: message.role,
        content
      })
    }
  }

  claudeRequest.messages = messages

  if (systemPrompt) {
    claudeRequest.system = systemPrompt
  }

  // ËΩ¨Êç¢ tools (function calling)
  if (rawRequest.tools && rawRequest.tools.length > 0) {
    claudeRequest.tools = rawRequest.tools.map((tool) => {
      if (tool.type === 'function') {
        return {
          name: tool.function.name,
          description: tool.function.description || '',
          input_schema: tool.function.parameters || { type: 'object', properties: {} }
        }
      }
      return tool
    })
  }

  // ËΩ¨Êç¢ÂÖ∂‰ªñÂèÇÊï∞
  if (rawRequest.temperature !== undefined) {
    claudeRequest.temperature = rawRequest.temperature
  }
  if (rawRequest.top_p !== undefined) {
    claudeRequest.top_p = rawRequest.top_p
  }
  if (rawRequest.stop) {
    claudeRequest.stop_sequences = Array.isArray(rawRequest.stop)
      ? rawRequest.stop
      : [rawRequest.stop]
  }

  logger.debug('üîÑ Translated OpenAI request to Claude format', {
    originalModel: rawRequest.model,
    claudeModel: claudeRequest.model,
    messageCount: messages.length,
    hasSystem: !!systemPrompt,
    hasTools: !!claudeRequest.tools
  })

  return claudeRequest
}

/**
 * Â∞Ü Claude ÊµÅÂºèÂìçÂ∫îËΩ¨Êç¢‰∏∫ OpenAI Ê†ºÂºè
 * 
 * Claude SSE ‰∫ã‰ª∂Á±ªÂûãÔºö
 * - message_start: Ê∂àÊÅØÂºÄÂßã
 * - content_block_start: ÂÜÖÂÆπÂùóÂºÄÂßã
 * - content_block_delta: ÂÜÖÂÆπÂ¢ûÈáèÔºàÂåÖÂê´textÔºâ
 * - content_block_stop: ÂÜÖÂÆπÂùóÁªìÊùü
 * - message_delta: Ê∂àÊÅØÂÖÉÊï∞ÊçÆÊõ¥Êñ∞
 * - message_stop: Ê∂àÊÅØÁªìÊùü
 * 
 * OpenAI SSEÊ†ºÂºèÔºö
 * data: {"id":"chatcmpl-xxx","choices":[{"index":0,"delta":{"content":"text"},"finish_reason":null}]}
 * 
 * @param {TranslateResponseOptions} options
 * @returns {string[]} SSEÊ†ºÂºèÁöÑÂìçÂ∫îÊï∞ÁªÑ
 */
function translateClaudeStreamResponseToOpenAI({ model, originalRequest, rawResponse, metadata }) {
  try {
    const lines = []

    // Ëß£Êûê Claude ÂìçÂ∫î
    let claudeData
    if (typeof rawResponse === 'string') {
      // Â§ÑÁêÜ SSE Ê†ºÂºè: "event: xxx\ndata: {...}\n\n"
      const eventMatch = rawResponse.match(/event:\s*(\w+)/)
      const dataMatch = rawResponse.match(/data:\s*({.+})/)

      if (dataMatch) {
        claudeData = JSON.parse(dataMatch[1])
        if (eventMatch) {
          claudeData._event = eventMatch[1]
        }
      } else {
        return []
      }
    } else {
      claudeData = rawResponse
    }

    // ÁîüÊàê OpenAI chunk
    const openaiChunk = {
      id: `chatcmpl-${Date.now()}`,
      object: 'chat.completion.chunk',
      created: Math.floor(Date.now() / 1000),
      model: model || originalRequest.model || 'gpt-4',
      choices: []
    }

    // Ê†πÊçÆ‰∏çÂêåÁöÑ Claude ‰∫ã‰ª∂Á±ªÂûãËΩ¨Êç¢
    const eventType = claudeData._event || claudeData.type

    if (eventType === 'message_start') {
      // Ê∂àÊÅØÂºÄÂßã - ÂèëÈÄÅ role
      openaiChunk.choices.push({
        index: 0,
        delta: { role: 'assistant' },
        finish_reason: null
      })
    } else if (eventType === 'content_block_delta') {
      // ÂÜÖÂÆπÂ¢ûÈáè - ÂèëÈÄÅÊñáÊú¨
      const text = claudeData.delta?.text || ''
      if (text) {
        openaiChunk.choices.push({
          index: 0,
          delta: { content: text },
          finish_reason: null
        })
      }
    } else if (eventType === 'message_delta') {
      // Ê∂àÊÅØÁªìÊùü - ÂèëÈÄÅ finish_reason
      const stopReason = claudeData.delta?.stop_reason
      if (stopReason) {
        openaiChunk.choices.push({
          index: 0,
          delta: {},
          finish_reason: stopReason === 'end_turn' ? 'stop' : stopReason
        })
      }
    } else if (eventType === 'message_stop') {
      // ÊúÄÁªàÁªìÊùüÊ†áËÆ∞
      lines.push('data: [DONE]\n\n')
      return lines
    }

    // Âè™ÊúâÂΩìÊúâ choices Êó∂ÊâçÂèëÈÄÅ
    if (openaiChunk.choices.length > 0) {
      lines.push(`data: ${JSON.stringify(openaiChunk)}\n\n`)
    }

    return lines
  } catch (error) {
    logger.error('‚ùå Failed to translate Claude stream response to OpenAI', {
      error: error.message,
      rawResponse: typeof rawResponse === 'string' ? rawResponse.substring(0, 200) : 'object'
    })
    return []
  }
}

/**
 * Â∞Ü Claude ÈùûÊµÅÂºèÂìçÂ∫îËΩ¨Êç¢‰∏∫ OpenAI Ê†ºÂºè
 * 
 * Claude ÂìçÂ∫îÊ†ºÂºèÔºö
 * {
 *   id: "msg_xxx",
 *   type: "message",
 *   role: "assistant",
 *   content: [{ type: "text", text: "response text" }],
 *   stop_reason: "end_turn",
 *   usage: { input_tokens: 10, output_tokens: 20 }
 * }
 * 
 * OpenAI ÂìçÂ∫îÊ†ºÂºèÔºö
 * {
 *   id: "chatcmpl-xxx",
 *   choices: [{
 *     index: 0,
 *     message: { role: "assistant", content: "response text" },
 *     finish_reason: "stop"
 *   }],
 *   usage: { prompt_tokens: 10, completion_tokens: 20, total_tokens: 30 }
 * }
 * 
 * @param {TranslateResponseOptions} options
 * @returns {Object} OpenAIÊ†ºÂºèÁöÑÂìçÂ∫î
 */
function translateClaudeNonStreamResponseToOpenAI({
  model,
  originalRequest,
  rawResponse,
  metadata
}) {
  try {
    const claudeData = typeof rawResponse === 'string' ? JSON.parse(rawResponse) : rawResponse

    const openaiResponse = {
      id: `chatcmpl-${Date.now()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: model || originalRequest.model || 'gpt-4',
      choices: [],
      usage: {
        prompt_tokens: claudeData.usage?.input_tokens || 0,
        completion_tokens: claudeData.usage?.output_tokens || 0,
        total_tokens:
          (claudeData.usage?.input_tokens || 0) + (claudeData.usage?.output_tokens || 0)
      }
    }

    // ÊèêÂèñÂÜÖÂÆπ
    let content = ''
    const toolCalls = []

    if (claudeData.content && Array.isArray(claudeData.content)) {
      for (const block of claudeData.content) {
        if (block.type === 'text') {
          content += block.text
        } else if (block.type === 'tool_use') {
          // ËΩ¨Êç¢ tool_use ‰∏∫ OpenAI ÁöÑ tool_calls Ê†ºÂºè
          toolCalls.push({
            id: block.id || `call_${Date.now()}`,
            type: 'function',
            function: {
              name: block.name,
              arguments: JSON.stringify(block.input || {})
            }
          })
        }
      }
    }

    const message = {
      role: 'assistant',
      content: content || null
    }

    if (toolCalls.length > 0) {
      message.tool_calls = toolCalls
    }

    openaiResponse.choices.push({
      index: 0,
      message,
      finish_reason: claudeData.stop_reason === 'end_turn' ? 'stop' : claudeData.stop_reason || 'stop'
    })

    logger.debug('üîÑ Translated Claude non-stream response to OpenAI format', {
      contentLength: content.length,
      toolCallsCount: toolCalls.length,
      usage: openaiResponse.usage
    })

    return openaiResponse
  } catch (error) {
    logger.error('‚ùå Failed to translate Claude response to OpenAI', {
      error: error.message,
      stack: error.stack
    })
    throw error
  }
}

module.exports = {
  translateOpenAIRequestToClaude,
  translateClaudeStreamResponseToOpenAI,
  translateClaudeNonStreamResponseToOpenAI
}
